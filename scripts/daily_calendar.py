#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ•èµ„æ—¥å†æ—¥å¸¸æ•°æ®é‡‡é›†ä¸å˜æ›´æ£€æµ‹
æ¯æ—¥è¿è¡Œï¼Œé‡‡é›†æœªæ¥æ•°æ®å¹¶æ£€æµ‹å˜æ›´
"""

import requests
import json
import hashlib
import time
import os
import re
import shutil
import calendar
import urllib.parse
from datetime import datetime, timedelta
from typing import List, Dict, Any
from dataclasses import dataclass, asdict
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
import random


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class StandardizedEvent:
    """æ ‡å‡†åŒ–äº‹ä»¶æ¨¡å‹"""
    platform: str
    event_id: str
    original_id: str
    event_date: str
    event_time: str = None
    event_datetime: str = None
    title: str = ""
    content: str = None
    category: str = None
    importance: int = None
    country: str = None
    city: str = None
    stocks: List[str] = None
    concepts: List[Dict[str, Any]] = None
    themes: List[str] = None
    data_status: str = "ACTIVE"
    is_new: bool = False
    discovery_date: str = ""
    raw_data: Dict[str, Any] = None
    created_at: str = ""
    
    def __post_init__(self):
        if self.stocks is None:
            self.stocks = []
        if self.concepts is None:
            self.concepts = []
        if self.themes is None:
            self.themes = []
        if self.raw_data is None:
            self.raw_data = {}
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        if not self.discovery_date:
            self.discovery_date = datetime.now().strftime('%Y-%m-%d')
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)

# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def generate_sign(params_dict):
    """ç”Ÿæˆè´¢è”ç¤¾APIè¯·æ±‚çš„ç­¾å"""
    sorted_data = sorted(params_dict.items(), key=lambda item: item[0])
    query_string = urllib.parse.urlencode(sorted_data)
    sha1_hash = hashlib.sha1(query_string.encode('utf-8')).hexdigest()
    sign = hashlib.md5(sha1_hash.encode('utf-8')).hexdigest()
    return sign

def extract_json_from_jsonp(jsonp_text: str, callback_name: str) -> Dict[str, Any]:
    """ä»JSONPå“åº”ä¸­æå–JSONæ•°æ®"""
    try:
        pattern = f'{callback_name}\\((.+)\\);?$'
        match = re.search(pattern, jsonp_text.strip())
        if match:
            json_str = match.group(1)
            return json.loads(json_str)
    except:
        pass
    return {}

def load_platform_data(platform: str, data_path: str) -> List[StandardizedEvent]:
    """ä»txtæ–‡ä»¶åŠ è½½å¹³å°æ•°æ®"""
    file_path = os.path.join(data_path, f"{platform}.txt")
    
    if not os.path.exists(file_path):
        return []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            json_content = f.read()
            data = json.loads(json_content)
        
        events = []
        for event_data in data.get('events', []):
            event = StandardizedEvent(**event_data)
            events.append(event)
        
        return events
    except Exception as e:
        print(f"åŠ è½½ {platform} æ•°æ®å¤±è´¥: {e}")
        return []

# ============================================================================
# å¹³å°æ•°æ®èŒƒå›´åŠ¨æ€æ£€æµ‹å™¨
# ============================================================================

class PlatformRangeDetector:
    """å¹³å°æ•°æ®èŒƒå›´åŠ¨æ€æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.range_cache = {}
    
    def get_platform_date_range(self, platform: str, start_date: str) -> str:
        """è·å–å¹³å°çš„å®é™…æ•°æ®èŒƒå›´"""
        cache_key = f"{platform}_{start_date}"
        
        if cache_key in self.range_cache:
            return self.range_cache[cache_key]
        
        if platform == "cls":
            max_date = self._detect_cls_max_date(start_date)
        elif platform == "jiuyangongshe":
            max_date = self._detect_jiuyan_max_date(start_date)
        elif platform == "tonghuashun":
            max_date = self._detect_tonghuashun_max_date(start_date)
        elif platform == "investing":
            max_date = self._detect_investing_max_date(start_date)
        elif platform == "eastmoney":
            max_date = self._detect_eastmoney_max_date(start_date)
        else:
            max_date = start_date
        
        self.range_cache[cache_key] = max_date
        return max_date
    
    def _detect_cls_max_date(self, start_date: str) -> str:
        """è´¢è”ç¤¾ï¼šé€šå¸¸æä¾›æœªæ¥6ä¸ªæœˆæ•°æ®"""
        test_date = (datetime.strptime(start_date, '%Y-%m-%d') + timedelta(days=180)).strftime('%Y-%m-%d')
        return test_date
    
    def _detect_jiuyan_max_date(self, start_date: str) -> str:
        """éŸ­ç ”å…¬ç¤¾ï¼šæµ‹è¯•åˆ°å¹´åº•"""
        return "2025-12-31"
    
    def _detect_tonghuashun_max_date(self, start_date: str) -> str:
        """åŒèŠ±é¡ºï¼šæµ‹è¯•åˆ°å¹´åº•"""
        return "2025-12-31"
    
    def _detect_investing_max_date(self, start_date: str) -> str:
        """è‹±ä¸ºè´¢æƒ…ï¼šæµ‹è¯•åˆ°æ˜å¹´åº•"""
        return "2025-12-31"
    
    def _detect_eastmoney_max_date(self, start_date: str) -> str:
        """ä¸œæ–¹è´¢å¯Œï¼šæµ‹è¯•åˆ°å¹´åº•"""
        return "2025-12-31"

# ============================================================================
# æœªæ¥æ•°æ®é‡‡é›†å™¨
# ============================================================================

class FutureDataCollector:
    """æœªæ¥æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self):
        self.base_path = "./data"
        self.current_path = os.path.join(self.base_path, "active", "current")
        self.range_detector = PlatformRangeDetector()
        self._ensure_directories()
    
    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        os.makedirs(self.current_path, exist_ok=True)
    
    def collect_all_future_data(self) -> Dict[str, List[StandardizedEvent]]:
        """é‡‡é›†æ‰€æœ‰å¹³å°çš„æœªæ¥æ•°æ®ï¼ˆåŠ¨æ€èŒƒå›´ï¼‰"""
        today = datetime.now().strftime('%Y-%m-%d')
        
        print(f"ğŸ”® å¼€å§‹é‡‡é›†æœªæ¥æ•°æ®ï¼ˆä» {today} å¼€å§‹ï¼ŒåŠ¨æ€æ£€æµ‹æœ€è¿œæ—¥æœŸï¼‰")
        print("=" * 60)
        
        results = {}
        total_events = 0
        
        # è´¢è”ç¤¾
        print(f"\nğŸ“¡ æ­£åœ¨é‡‡é›† cls æœªæ¥æ•°æ®...")
        max_date = self.range_detector.get_platform_date_range('cls', today)
        print(f"   ğŸ“… cls æ•°æ®èŒƒå›´: {today} â†’ {max_date}")
        cls_events = self._collect_cls_future_dynamic(today, max_date)
        results['cls'] = cls_events
        total_events += len(cls_events)
        print(f"âœ… cls é‡‡é›†å®Œæˆï¼Œå…± {len(cls_events)} ä¸ªäº‹ä»¶")
        
        # éŸ­ç ”å…¬ç¤¾
        print(f"\nğŸ“¡ æ­£åœ¨é‡‡é›† jiuyangongshe æœªæ¥æ•°æ®...")
        max_date = self.range_detector.get_platform_date_range('jiuyangongshe', today)
        print(f"   ğŸ“… jiuyangongshe æ•°æ®èŒƒå›´: {today} â†’ {max_date}")
        jiuyan_events = self._collect_jiuyan_future_dynamic(today, max_date)
        results['jiuyangongshe'] = jiuyan_events
        total_events += len(jiuyan_events)
        print(f"âœ… jiuyangongshe é‡‡é›†å®Œæˆï¼Œå…± {len(jiuyan_events)} ä¸ªäº‹ä»¶")
        
        # åŒèŠ±é¡º
        print(f"\nğŸ“¡ æ­£åœ¨é‡‡é›† tonghuashun æœªæ¥æ•°æ®...")
        max_date = self.range_detector.get_platform_date_range('tonghuashun', today)
        print(f"   ğŸ“… tonghuashun æ•°æ®èŒƒå›´: {today} â†’ {max_date}")
        ths_events = self._collect_tonghuashun_future_dynamic(today, max_date)
        results['tonghuashun'] = ths_events
        total_events += len(ths_events)
        print(f"âœ… tonghuashun é‡‡é›†å®Œæˆï¼Œå…± {len(ths_events)} ä¸ªäº‹ä»¶")
        
        # è‹±ä¸ºè´¢æƒ…
        print(f"\nğŸ“¡ æ­£åœ¨é‡‡é›† investing æœªæ¥æ•°æ®...")
        max_date = self.range_detector.get_platform_date_range('investing', today)
        print(f"   ğŸ“… investing æ•°æ®èŒƒå›´: {today} â†’ {max_date}")
        inv_events = self._collect_investing_future_dynamic(today, max_date)
        results['investing'] = inv_events
        total_events += len(inv_events)
        print(f"âœ… investing é‡‡é›†å®Œæˆï¼Œå…± {len(inv_events)} ä¸ªäº‹ä»¶")
        
        # ä¸œæ–¹è´¢å¯Œ
        print(f"\nğŸ“¡ æ­£åœ¨é‡‡é›† eastmoney æœªæ¥æ•°æ®...")
        max_date = self.range_detector.get_platform_date_range('eastmoney', today)
        print(f"   ğŸ“… eastmoney æ•°æ®èŒƒå›´: {today} â†’ {max_date}")
        em_events = self._collect_eastmoney_future_dynamic(today, max_date)
        results['eastmoney'] = em_events
        total_events += len(em_events)
        print(f"âœ… eastmoney é‡‡é›†å®Œæˆï¼Œå…± {len(em_events)} ä¸ªäº‹ä»¶")
        
        print(f"\nğŸ“Š æ€»è®¡é‡‡é›† {total_events} ä¸ªæœªæ¥äº‹ä»¶")
        return results
    
    def _collect_cls_future_dynamic(self, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """é‡‡é›†è´¢è”ç¤¾æœªæ¥æ•°æ®"""
        params = {
            "app": "CailianpressWeb",
            "flag": "0",  # ä»ä»Šä»¥åçš„æ•°æ®
            "os": "web",
            "sv": "8.4.6",
            "token": "65EOORtcq9jy9667Vw0qugGnpcm4vU894112432",
            "type": "0",
            "uid": "4112432"
        }
        params["sign"] = generate_sign(params)
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "application/json, text/plain, */*",
            "Referer": "https://www.cls.cn/investKalendar"
        }
        
        try:
            response = requests.get(
                "https://www.cls.cn/api/calendar/web/list", 
                params=params, headers=headers, timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                events = []
                
                for day_data in data.get('data', []):
                    date = day_data.get('calendar_day')
                    
                    # åªè¦start_dateåŠä»¥åä¸”ä¸è¶…è¿‡end_dateçš„æ•°æ®
                    if not date or date < start_date or date > end_date:
                        continue
                    
                    for item in day_data.get('items', []):
                        event = StandardizedEvent(
                            platform="cls",
                            event_id=f"cls_{item.get('id')}_{date.replace('-', '')}_{item.get('type', 0)}",
                            original_id=str(item.get('id')),
                            event_date=date,
                            event_time=self._extract_time(item.get('calendar_time')),
                            event_datetime=item.get('calendar_time'),
                            title=item.get('title', ''),
                            category=self._get_cls_category(item.get('type')),
                            importance=self._get_cls_importance(item),
                            country=self._extract_cls_country(item),
                            raw_data=item
                        )
                        events.append(event)
                
                return events
            else:
                return []
        except Exception as e:
            print(f"è´¢è”ç¤¾APIè¯·æ±‚å¤±è´¥: {e}")
            return []
            
    def _collect_jiuyan_future_dynamic(self, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """é‡‡é›†éŸ­ç ”å…¬ç¤¾æœªæ¥æ•°æ® - ä¿®å¤ç‰ˆ"""
        all_events = []  # æ”¹ä¸ºäº‹ä»¶åˆ—è¡¨
        
        # æŒ‰æœˆé‡‡é›†åˆ°end_date
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        
        current_dt = start_dt.replace(day=1)  # ä»æœˆåˆå¼€å§‹ï¼Œé¿å…æ—¥æœŸé—®é¢˜
        
        while current_dt <= end_dt:
            year, month = current_dt.year, current_dt.month
            print(f"   ğŸ“… é‡‡é›† {year}å¹´{month}æœˆ...")
            
            try:
                events = self._get_jiuyan_month_data(year, month, start_date, end_date, is_future=True)
                if events:
                    all_events.extend(events)  # æ·»åŠ åˆ°æ€»åˆ—è¡¨
                    print(f"      âœ… {year}å¹´{month}æœˆ: {len(events)} ä¸ªäº‹ä»¶")
                else:
                    print(f"      âš ï¸ {year}å¹´{month}æœˆ: æ— æ•°æ®")
                    
                time.sleep(0.5)
                
            except Exception as e:
                print(f"      âŒ {year}å¹´{month}æœˆé‡‡é›†å¤±è´¥: {e}")
            
            # å®‰å…¨åœ°ç§»åŠ¨åˆ°ä¸‹ä¸ªæœˆ
            try:
                if current_dt.month == 12:
                    current_dt = current_dt.replace(year=current_dt.year + 1, month=1)
                else:
                    current_dt = current_dt.replace(month=current_dt.month + 1)
            except ValueError as e:
                print(f"      âŒ æ—¥æœŸè®¡ç®—é”™è¯¯: {e}")
                break
        
        print(f"   ğŸ“Š éŸ­ç ”å…¬ç¤¾æ€»è®¡: {len(all_events)} ä¸ªäº‹ä»¶")
        return all_events  # è¿”å›äº‹ä»¶åˆ—è¡¨ï¼Œä¸æ˜¯æ•°é‡
    
    def _collect_tonghuashun_future_dynamic(self, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """é‡‡é›†åŒèŠ±é¡ºæœªæ¥æ•°æ® - ä¿®å¤ç‰ˆ"""
        all_events = []
        
        # æŒ‰æœˆé‡‡é›†åˆ°end_date
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        
        current_dt = start_dt.replace(day=1)  # ä»æœˆåˆå¼€å§‹
        
        while current_dt <= end_dt:
            year, month = current_dt.year, current_dt.month
            print(f"   ğŸ“… é‡‡é›† {year}å¹´{month}æœˆ...")
            
            try:
                events = self._get_tonghuashun_month_data(year, month, start_date, end_date, is_future=True)
                if events:
                    all_events.extend(events)
                    print(f"      âœ… {year}å¹´{month}æœˆ: {len(events)} ä¸ªäº‹ä»¶")
                else:
                    print(f"      âš ï¸ {year}å¹´{month}æœˆ: æ— æ•°æ®")
                    
                time.sleep(0.5)
                
            except Exception as e:
                print(f"      âŒ {year}å¹´{month}æœˆé‡‡é›†å¤±è´¥: {e}")
            
            # å®‰å…¨åœ°ç§»åŠ¨åˆ°ä¸‹ä¸ªæœˆ
            try:
                if current_dt.month == 12:
                    current_dt = current_dt.replace(year=current_dt.year + 1, month=1)
                else:
                    current_dt = current_dt.replace(month=current_dt.month + 1)
            except ValueError as e:
                print(f"      âŒ æ—¥æœŸè®¡ç®—é”™è¯¯: {e}")
                break
        
        print(f"   ğŸ“Š åŒèŠ±é¡ºæ€»è®¡: {len(all_events)} ä¸ªäº‹ä»¶")
        return all_events

    def _collect_investing_future_dynamic(self, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """é‡‡é›†è‹±ä¸ºè´¢æƒ…æœªæ¥æ•°æ®ï¼ˆå¹¶å‘æŒ‰å¤©é‡‡é›†ï¼‰"""
        print(f"   ğŸ”„ è‹±ä¸ºè´¢æƒ…å¹¶å‘æŒ‰å¤©é‡‡é›†: {start_date} â†’ {end_date}")
        
        # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
        date_list = []
        current_date = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        
        while current_date <= end_dt:
            date_list.append(current_date.strftime('%Y-%m-%d'))
            current_date += timedelta(days=1)
        
        print(f"   ğŸ“… æ€»å…±éœ€è¦é‡‡é›† {len(date_list)} å¤©çš„æ•°æ®")
        
        all_events = []
        max_workers = 5  # å¹¶å‘çº¿ç¨‹æ•°
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘é‡‡é›†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_date = {
                executor.submit(self._request_investing_single_day_with_retry, date): date 
                for date in date_list
            }
            
            completed_count = 0
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_date):
                date = future_to_date[future]
                completed_count += 1
                
                try:
                    day_events = future.result()
                    if day_events:
                        all_events.extend(day_events)
                    
                    # æ¯50å¤©æˆ–æœ€åæ˜¾ç¤ºè¿›åº¦
                    if completed_count % 50 == 0 or completed_count == len(date_list):
                        print(f"      ğŸ“Š è¿›åº¦: {completed_count}/{len(date_list)} å¤©å®Œæˆï¼Œå·²è·å– {len(all_events)} ä¸ªäº‹ä»¶")
                        
                except Exception as e:
                    print(f"      âŒ {date} é‡‡é›†å¤±è´¥: {e}")
        
        print(f"   ğŸ“Š è‹±ä¸ºè´¢æƒ…æ€»è®¡: {len(all_events)} ä¸ªäº‹ä»¶ (å¹¶å‘é‡‡é›† {len(date_list)} å¤©)")
        return all_events

    def _request_investing_single_day_with_retry(self, date: str, max_retries: int = 3) -> List[StandardizedEvent]:
        """è¯·æ±‚è‹±ä¸ºè´¢æƒ…å•å¤©æ•°æ®ï¼ˆå¸¦é‡è¯•å’Œéšæœºå»¶è¿Ÿï¼‰"""
        for attempt in range(max_retries):
            try:
                # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…å¹¶å‘è¯·æ±‚è¿‡äºé›†ä¸­
                delay = random.uniform(0.2, 0.8)
                time.sleep(delay)
                
                return self._request_investing_single_day(date)
                
            except Exception as e:
                if attempt == max_retries - 1:
                    # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
                    return []
                else:
                    # é‡è¯•å‰ç­‰å¾…
                    retry_delay = random.uniform(1.0, 2.0)
                    time.sleep(retry_delay)
        
        return []

    
    def _collect_eastmoney_future_dynamic(self, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """é‡‡é›†ä¸œæ–¹è´¢å¯Œæœªæ¥æ•°æ®"""
        params = {
            "fromdate": start_date,
            "todate": end_date,
            "option": "xsap,xgsg,tfpxx,hsgg,nbjb,jjsj,hyhy,gddh"
        }
        
        headers = {
            "Host": "data.eastmoney.com",
            "Accept": "application/json, text/javascript, */*; q=0.01",
            "X-Requested-With": "XMLHttpRequest",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Referer": "https://data.eastmoney.com/dcrl/dashi.html"
        }
        
        try:
            response = requests.get(
                "https://data.eastmoney.com/dataapi/dcrl/dstx",
                params=params, headers=headers, timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                events = []
                
                # å®‰å…¨è·å–æ•°æ®é•¿åº¦ï¼Œå¤„ç†Noneå€¼
                def safe_len(data_list):
                    return len(data_list) if data_list is not None else 0
                
                print(f"   ğŸ” ä¸œæ–¹è´¢å¯ŒåŸå§‹æ•°æ®ç»Ÿè®¡:")
                print(f"      ä¼‘å¸‚å®‰æ’(xsap): {safe_len(data.get('xsap'))} æ¡")
                print(f"      æ–°è‚¡ç”³è´­(xgsg): {safe_len(data.get('xgsg'))} æ¡")
                print(f"      åœå¤ç‰Œä¿¡æ¯(tfpxx): {safe_len(data.get('tfpxx'))} æ¡")
                print(f"      Aè‚¡å…¬å‘Š(hsgg): {safe_len(data.get('hsgg'))} æ¡")
                print(f"      å¹´æŠ¥å­£æŠ¥(nbjb): {safe_len(data.get('nbjb'))} æ¡")
                print(f"      ç»æµæ•°æ®(jjsj): {safe_len(data.get('jjsj'))} æ¡")
                print(f"      è¡Œä¸šä¼šè®®(hyhy): {safe_len(data.get('hyhy'))} æ¡")
                print(f"      è‚¡ä¸œå¤§ä¼š(gddh): {safe_len(data.get('gddh'))} æ¡")
                
                # å¤„ç†å„ç±»æ•°æ®
                events.extend(self._process_eastmoney_xsap(data.get('xsap') or [], start_date, end_date))
                events.extend(self._process_eastmoney_xgsg(data.get('xgsg') or [], start_date, end_date))
                events.extend(self._process_eastmoney_tfpxx(data.get('tfpxx') or [], start_date, end_date))
                events.extend(self._process_eastmoney_hsgg(data.get('hsgg') or [], start_date, end_date))
                events.extend(self._process_eastmoney_nbjb(data.get('nbjb') or [], start_date, end_date))
                events.extend(self._process_eastmoney_jjsj(data.get('jjsj') or [], start_date, end_date))
                events.extend(self._process_eastmoney_hyhy(data.get('hyhy') or [], start_date, end_date))
                events.extend(self._process_eastmoney_gddh(data.get('gddh') or [], start_date, end_date))
                
                print(f"   âœ… ä¸œæ–¹è´¢å¯Œè¿‡æ»¤åäº‹ä»¶: {len(events)} ä¸ª")
                return events
            else:
                return []
        except Exception as e:
            print(f"ä¸œæ–¹è´¢å¯ŒAPIè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    # è´¢è”ç¤¾è¾…åŠ©æ–¹æ³•
    def _extract_time(self, datetime_str: str) -> str:
        if not datetime_str:
            return None
        try:
            dt = datetime.fromisoformat(datetime_str.replace('Z', '+00:00'))
            return dt.strftime('%H:%M:%S')
        except:
            return None
    
    def _get_cls_category(self, event_type: int) -> str:
        type_map = {1: 'ç»æµæ•°æ®', 2: 'äº‹ä»¶å…¬å‘Š', 3: 'å‡æ—¥'}
        return type_map.get(event_type, 'å…¶ä»–')
    
    def _get_cls_importance(self, item: Dict) -> int:
        if item.get('type') == 1 and item.get('economic'):
            return item.get('economic', {}).get('star', 3)
        elif item.get('type') == 2 and item.get('event'):
            return item.get('event', {}).get('star', 3)
        return 3
    
    def _extract_cls_country(self, item: Dict) -> str:
        if item.get('economic'):
            return item.get('economic', {}).get('country')
        elif item.get('event'):
            return item.get('event', {}).get('country')
        return None
    
    # éŸ­ç ”å…¬ç¤¾è¾…åŠ©æ–¹æ³•
    def _get_jiuyan_month_data(self, year: int, month: int, start_date: str, end_date: str, is_future: bool = False) -> List[StandardizedEvent]:
        """è·å–éŸ­ç ”å…¬ç¤¾æœˆåº¦æ•°æ®"""
        date_param = f"{year}-{month:02d}"
        
        headers = {
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'timestamp': str(int(time.time() * 1000)),
            'platform': '3',
            'token': '094cbed7fa79612f2ba4fcd34b191d99',
            'Origin': 'https://www.jiuyangongshe.com',
            'Referer': 'https://www.jiuyangongshe.com/'
        }
        
        payload = {"date": date_param}
        
        try:
            response = requests.post(
                "https://app.jiuyangongshe.com/jystock-app/api/v1/timeline/list",
                headers=headers, json=payload, timeout=10
            )
            
            if response.status_code == 200:
                month_data = response.json()
                events = []
                
                for day_data in month_data.get('data', []):
                    date = day_data.get('date')
                    
                    # è¿‡æ»¤æ—¥æœŸèŒƒå›´
                    if not date or date < start_date or date > end_date:
                        continue
                    
                    # éªŒè¯æ—¥æœŸæœ‰æ•ˆæ€§
                    try:
                        datetime.strptime(date, '%Y-%m-%d')
                    except ValueError:
                        print(f"        âš ï¸ æ— æ•ˆæ—¥æœŸ: {date}")
                        continue
                    
                    for item in day_data.get('list', []):
                        try:
                            timeline = item.get('timeline', {})
                            event = StandardizedEvent(
                                platform="jiuyangongshe",
                                event_id=f"jygs_{item.get('article_id', '')}_{timeline.get('timeline_id', '')}_{date.replace('-', '')}",
                                original_id=item.get('article_id', ''),
                                event_date=date,
                                title=item.get('title', ''),
                                content=item.get('content', ''),
                                importance=max(1, min(5, 7 - timeline.get('grade', 6))),
                                country='ä¸­å›½',
                                themes=[theme.get('name', '') for theme in timeline.get('theme_list', [])],
                                raw_data=item
                            )
                            events.append(event)
                        except Exception as e:
                            print(f"        âŒ äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
                            continue
                
                return events
            else:
                return []
        except Exception as e:
            print(f"éŸ­ç ”å…¬ç¤¾APIè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def _get_tonghuashun_month_data(self, year: int, month: int, start_date: str, end_date: str, is_future: bool = False) -> List[StandardizedEvent]:
        """è·å–åŒèŠ±é¡ºæœˆåº¦æ•°æ®"""
        date_param = f"{year}{month:02d}"
        
        params = {
            'callback': 'callback_dt',
            'type': 'data',
            'date': date_param
        }
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': 'https://stock.10jqka.com.cn/',
            'Accept': '*/*'
        }
        
        try:
            response = requests.get(
                "https://comment.10jqka.com.cn/tzrl/getTzrlData.php",
                params=params, headers=headers, timeout=10
            )
            
            if response.status_code == 200:
                json_data = extract_json_from_jsonp(response.text, 'callback_dt')
                events = []
                
                for day_data in json_data.get('data', []):
                    date = day_data.get('date')
                    
                    # è¿‡æ»¤æ—¥æœŸèŒƒå›´
                    if not date or date < start_date or date > end_date:
                        continue
                    
                    # éªŒè¯æ—¥æœŸæœ‰æ•ˆæ€§
                    try:
                        datetime.strptime(date, '%Y-%m-%d')
                    except ValueError:
                        print(f"        âš ï¸ æ— æ•ˆæ—¥æœŸ: {date}")
                        continue
                    
                    day_events = day_data.get('events', [])
                    concepts = day_data.get('concept', [])
                    
                    for i, event_data in enumerate(day_events):
                        if isinstance(event_data, list) and len(event_data) > 0:
                            try:
                                title = event_data[0] if event_data[0] else ""
                                title_hash = hashlib.md5(title.encode('utf-8')).hexdigest()[:8]
                                concept_info = concepts[i] if i < len(concepts) else []
                                
                                event = StandardizedEvent(
                                    platform="tonghuashun",
                                    event_id=f"ths_{date.replace('-', '')}_{i}_{title_hash}",
                                    original_id=f"{date}_{i}",
                                    event_date=date,
                                    title=title,
                                    importance=3,
                                    country='ä¸­å›½',
                                    concepts=[{"code": c.get("code"), "name": c.get("name")} for c in concept_info] if concept_info else [],
                                    raw_data={"event": event_data, "concept": concept_info}
                                )
                                events.append(event)
                            except Exception as e:
                                print(f"        âŒ äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
                                continue
                
                return events
            else:
                return []
        except Exception as e:
            print(f"åŒèŠ±é¡ºAPIè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    # è‹±ä¸ºè´¢æƒ…è¾…åŠ©æ–¹æ³•
    def _request_investing_single_day(self, date: str) -> List[StandardizedEvent]:
        """è¯·æ±‚è‹±ä¸ºè´¢æƒ…å•å¤©æ•°æ®"""
        countries = [37, 46, 6, 110, 14, 48, 32, 17, 10, 36, 43, 35, 72, 22, 41, 25, 12, 5, 4, 26, 178, 11, 39, 42]
        
        # æ„å»ºè¯·æ±‚ä½“ï¼ˆå•å¤©ï¼‰
        payload = ""
        for country in countries:
            payload += f"country%5B%5D={country}&"
        payload += f"dateFrom={date}&dateTo={date}&timeZone=28&timeFilter=timeRemain&currentTab=custom&limit_from=0"
        
        headers = {
            "Host": "cn.investing.com",
            "Connection": "keep-alive",
            "sec-ch-ua": '"Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"',
            "sec-ch-ua-mobile": "?0",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Content-Type": "application/x-www-form-urlencoded",
            "Accept": "*/*",
            "X-Requested-With": "XMLHttpRequest",
            "sec-ch-ua-platform": '"Windows"',
            "Origin": "https://cn.investing.com",
            "Sec-Fetch-Site": "same-origin",
            "Sec-Fetch-Mode": "cors",
            "Sec-Fetch-Dest": "empty",
            "Referer": "https://cn.investing.com/economic-calendar/",
            "Accept-Encoding": "gzip, deflate, br, zstd",
            "Accept-Language": "zh-CN,zh;q=0.9"
        }
        
        try:
            response = requests.post(
                "https://cn.investing.com/economic-calendar/Service/getCalendarFilteredData",
                headers=headers, data=payload, timeout=15
            )
            
            if response.status_code == 200:
                html_content = response.text
                
                # æ£€æŸ¥æ˜¯å¦è¿”å›ç©ºç»“æœ
                if len(html_content.strip()) < 100:
                    return []
                
                # å¤„ç†å¯èƒ½çš„JSONåµŒå¥—
                try:
                    json_data = json.loads(html_content)
                    if 'data' in json_data:
                        html_content = json_data['data']
                    elif isinstance(json_data, dict) and len(json_data) == 0:
                        return []
                except json.JSONDecodeError:
                    pass
                
                # å¤„ç†è½¬ä¹‰å­—ç¬¦
                if '\\u' in html_content or '\\"' in html_content:
                    html_content = html_content.encode().decode('unicode_escape')
                    html_content = html_content.replace('\\"', '"').replace('\\/', '/')
                
                # æ£€æŸ¥HTMLå†…å®¹æ˜¯å¦åŒ…å«äº‹ä»¶æ•°æ®
                if 'js-event-item' not in html_content and 'eventRowId_' not in html_content:
                    return []
                
                return self._parse_investing_html_simple(html_content, date)
            else:
                return []
        except Exception as e:
            return []
    
    def _parse_investing_html_simple(self, html_content: str, date: str) -> List[StandardizedEvent]:
        """è§£æè‹±ä¸ºè´¢æƒ…HTMLæ•°æ®"""
        events = []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            event_rows = soup.find_all('tr', class_=re.compile(r'js-event-item'))
            
            if not event_rows:
                event_rows = soup.find_all('tr', id=re.compile(r'eventRowId_'))
            
            for row in event_rows:
                event_data = self._extract_investing_event_enhanced(row)
                if event_data and event_data.get('event_name'):
                    event_date = self._extract_date_from_datetime(event_data.get('datetime'))
                    
                    # åªè¦å½“å¤©çš„æ•°æ®
                    if event_date == date:
                        # æ„å»ºå†…å®¹å­—ç¬¦ä¸²ï¼ˆåŒ…å«æ•°å€¼ä¿¡æ¯ï¼‰
                        content_parts = []
                        if event_data.get('actual'):
                            content_parts.append(f"å®é™…å€¼: {event_data.get('actual')}")
                        if event_data.get('forecast'):
                            content_parts.append(f"é¢„æµ‹å€¼: {event_data.get('forecast')}")
                        if event_data.get('previous'):
                            content_parts.append(f"å‰å€¼: {event_data.get('previous')}")
                        
                        content = " | ".join(content_parts) if content_parts else None
                        
                        event = StandardizedEvent(
                            platform="investing",
                            event_id=f"inv_{event_data.get('event_attr_id', '')}_{event_data.get('datetime', '').replace('/', '').replace(' ', '').replace(':', '')}",
                            original_id=event_data.get('event_id', ''),
                            event_date=event_date,
                            event_time=event_data.get('time'),
                            event_datetime=event_data.get('datetime'),
                            title=event_data.get('event_name', ''),
                            content=content,
                            importance=event_data.get('importance', 1),
                            country=event_data.get('country'),
                            raw_data=event_data
                        )
                        events.append(event)
        except Exception as e:
            print(f"è‹±ä¸ºè´¢æƒ…HTMLè§£æå¤±è´¥: {e}")
        
        return events
    
    def _extract_investing_event_enhanced(self, row) -> Dict[str, Any]:
        """å¢å¼ºç‰ˆè‹±ä¸ºè´¢æƒ…äº‹ä»¶æ•°æ®æå–"""
        event = {}
        cells = row.find_all('td')
        
        if len(cells) < 4:
            return None
        
        event['event_id'] = row.get('id', '')
        event['event_attr_id'] = row.get('event_attr_ID', '')
        event['datetime'] = row.get('data-event-datetime', '')
        
        try:
            # ç¬¬1åˆ—ï¼šæ—¶é—´
            if len(cells) > 0:
                event['time'] = cells[0].get_text(strip=True)
            
            # ç¬¬2åˆ—ï¼šå›½å®¶
            if len(cells) > 1:
                flag_span = cells[1].find('span', class_=re.compile(r'ceFlags'))
                if flag_span:
                    event['country'] = flag_span.get('title', '')
            
            # ç¬¬3åˆ—ï¼šé‡è¦æ€§
            if len(cells) > 2:
                full_icons = cells[2].find_all('i', class_='grayFullBullishIcon')
                event['importance'] = len(full_icons) if full_icons else 1
            
            # ç¬¬4åˆ—ï¼šäº‹ä»¶åç§°
            if len(cells) > 3:
                event_cell = cells[3]
                link = event_cell.find('a')
                if link:
                    event['event_name'] = link.get_text(strip=True)
                else:
                    event['event_name'] = event_cell.get_text(strip=True)
            
            # ç¬¬5åˆ—ï¼šå®é™…å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
            if len(cells) > 4:
                actual_value = cells[4].get_text(strip=True)
                if actual_value and actual_value not in ['--', '']:
                    event['actual'] = actual_value
            
            # ç¬¬6åˆ—ï¼šé¢„æµ‹å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
            if len(cells) > 5:
                forecast_value = cells[5].get_text(strip=True)
                if forecast_value and forecast_value not in ['--', '']:
                    event['forecast'] = forecast_value
            
            # ç¬¬7åˆ—ï¼šå‰å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
            if len(cells) > 6:
                previous_value = cells[6].get_text(strip=True)
                if previous_value and previous_value not in ['--', '']:
                    event['previous'] = previous_value
        
        except Exception as e:
            print(f"è‹±ä¸ºè´¢æƒ…äº‹ä»¶æå–å¤±è´¥: {e}")
            return None
        
        return event
    
    def _extract_date_from_datetime(self, datetime_str: str) -> str:
        """ä»datetimeå­—ç¬¦ä¸²ä¸­æå–æ—¥æœŸ"""
        if not datetime_str:
            return ""
        try:
            date_part = datetime_str.split(' ')[0]
            return date_part.replace('/', '-')
        except:
            return ""
    
    # ä¸œæ–¹è´¢å¯Œè¾…åŠ©æ–¹æ³•
    def _extract_date_fixed(self, date_str: str) -> str:
        """ä¿®å¤ç‰ˆæ—¥æœŸæå–"""
        if not date_str:
            return ""
        try:
            if ' ' in date_str:
                return date_str.split(' ')[0]
            return date_str
        except Exception as e:
            return ""
    
    def _extract_time_fixed(self, datetime_str: str) -> str:
        """ä¿®å¤ç‰ˆæ—¶é—´æå–"""
        if not datetime_str:
            return None
        try:
            if ' ' in datetime_str:
                parts = datetime_str.split(' ')
                if len(parts) > 1 and parts[1] != "00:00:00":
                    return parts[1]
        except:
            return None
    
    def _process_eastmoney_xsap(self, xsap_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†ä¼‘å¸‚å®‰æ’æ•°æ®"""
        events = []
        for item in xsap_data:
            if not item:
                continue
            item_date = self._extract_date_fixed(item.get('SDATE'))
            if item_date and start_date <= item_date <= end_date:
                event = StandardizedEvent(
                    platform="eastmoney",
                    event_id=f"em_xsap_{item_date.replace('-', '')}_{hash(item.get('HOLIDAY', ''))}",
                    original_id=f"xsap_{item.get('MKT', '')}_{item_date}",
                    event_date=item_date,
                    event_time=self._extract_time_fixed(item.get('SDATE')),
                    event_datetime=item.get('SDATE'),
                    title=f"{item.get('MKT', '')} - {item.get('HOLIDAY', '')}",
                    category='ä¼‘å¸‚å®‰æ’',
                    importance=2,
                    country='ä¸­å›½',
                    raw_data=item
                )
                events.append(event)
        return events
    
    def _process_eastmoney_xgsg(self, xgsg_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†æ–°è‚¡ç”³è´­æ•°æ®"""
        events = []
        for item in xgsg_data:
            if not item:
                continue
            item_date = self._extract_date_fixed(item.get('APPLY_DATE'))
            if item_date and start_date <= item_date <= end_date:
                event = StandardizedEvent(
                    platform="eastmoney",
                    event_id=f"em_xgsg_{item.get('SECURITY_CODE', '')}_{item_date.replace('-', '')}",
                    original_id=item.get('SECURITY_CODE', ''),
                    event_date=item_date,
                    title=f"{item.get('SECURITY_NAME_ABBR', '')}æ–°è‚¡ç”³è´­",
                    content=f"ç”³è´­ä»£ç : {item.get('APPLY_CODE', '')}, å‘è¡Œä»·: {item.get('ISSUE_PRICE', '')}, å‘è¡Œé‡: {item.get('ONLINE_ISSUE_LWR', '')}ä¸‡è‚¡",
                    category='æ–°è‚¡ç”³è´­',
                    importance=3,
                    country='ä¸­å›½',
                    stocks=[item.get('SECURITY_CODE', '')] if item.get('SECURITY_CODE') else [],
                    raw_data=item
                )
                events.append(event)
        return events
    
    def _process_eastmoney_tfpxx(self, tfpxx_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†åœå¤ç‰Œä¿¡æ¯ - ä¿®å¤ç‰ˆ"""
        events = []
        
        print(f"      ğŸ” å¤„ç†åœå¤ç‰Œä¿¡æ¯: è¾“å…¥ {len(tfpxx_data)} æ¡")
        
        for tfpxx_item in tfpxx_data:
            if not tfpxx_item:
                continue
            
            # æ•°æ®ç»“æ„ï¼štfpxx_itemåŒ…å«Dateå’ŒDataå­—æ®µ
            item_date = self._extract_date_fixed(tfpxx_item.get('Date'))
            data_list = tfpxx_item.get('Data', [])
            
            print(f"      ğŸ“… æ—¥æœŸ: {item_date}, åœå¤ç‰Œè‚¡ç¥¨: {len(data_list)} åª")
            
            if item_date and start_date <= item_date <= end_date:
                for i, stock_data in enumerate(data_list):
                    if not stock_data:
                        continue
                    
                    stock_code = stock_data.get('Scode', '')
                    stock_name = stock_data.get('Sname', '')
                    
                    event = StandardizedEvent(
                        platform="eastmoney",
                        event_id=f"em_tfpxx_{stock_code}_{item_date.replace('-', '')}_{i}",
                        original_id=stock_code,
                        event_date=item_date,
                        title=f"{stock_name}åœå¤ç‰Œ",
                        content=f"è‚¡ç¥¨ä»£ç : {stock_code}, è‚¡ç¥¨åç§°: {stock_name}",
                        category='åœå¤ç‰Œä¿¡æ¯',
                        importance=2,
                        country='ä¸­å›½',
                        stocks=[stock_code] if stock_code else [],
                        raw_data={
                            'stock_code': stock_code,
                            'stock_name': stock_name,
                            'date': item_date
                        }
                    )
                    events.append(event)
                
                print(f"      âœ… {item_date} åˆ›å»ºäº† {len(data_list)} ä¸ªåœå¤ç‰Œäº‹ä»¶")
        
        print(f"      ğŸ“Š åœå¤ç‰Œä¿¡æ¯å¤„ç†å®Œæˆ: {len(events)} ä¸ªæœ‰æ•ˆäº‹ä»¶")
        return events

    

    def _process_eastmoney_hsgg(self, hsgg_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†Aè‚¡å…¬å‘Š - ä¿®å¤ç‰ˆ"""
        events = []
        
        print(f"      ğŸ” å¤„ç†Aè‚¡å…¬å‘Šæ•°æ®: è¾“å…¥ {len(hsgg_data)} æ¡")
        
        for hsgg_item in hsgg_data:
            if not hsgg_item:
                continue
            
            # æ–°çš„æ•°æ®ç»“æ„ï¼šhsgg_itemåŒ…å«Dateå’ŒDataå­—æ®µ
            item_date = self._extract_date_fixed(hsgg_item.get('Date'))
            total_count = hsgg_item.get('TotalCount', 0)
            data_list = hsgg_item.get('Data', [])
            
            print(f"      ğŸ“… æ—¥æœŸ: {item_date}, æ€»æ•°: {total_count}, å½“æ—¥æ•°æ®: {len(data_list)} æ¡")
            
            if item_date and start_date <= item_date <= end_date:
                # å¤„ç†å½“æ—¥çš„æ‰€æœ‰è‚¡ç¥¨å…¬å‘Š
                for i, stock_data in enumerate(data_list):
                    if not stock_data:
                        continue
                    
                    stock_code = stock_data.get('Scode', '')
                    stock_name = stock_data.get('Sname', '')
                    
                    event = StandardizedEvent(
                        platform="eastmoney",
                        event_id=f"em_hsgg_{stock_code}_{item_date.replace('-', '')}_{i}",
                        original_id=stock_code,
                        event_date=item_date,
                        title=f"{stock_name}å‘å¸ƒå…¬å‘Š",
                        content=f"è‚¡ç¥¨ä»£ç : {stock_code}, è‚¡ç¥¨åç§°: {stock_name}",
                        category='Aè‚¡å…¬å‘Š',
                        importance=3,
                        country='ä¸­å›½',
                        stocks=[stock_code] if stock_code else [],
                        raw_data={
                            'stock_code': stock_code,
                            'stock_name': stock_name,
                            'date': item_date,
                            'total_count': total_count
                        }
                    )
                    events.append(event)
                
                print(f"      âœ… {item_date} åˆ›å»ºäº† {len(data_list)} ä¸ªAè‚¡å…¬å‘Šäº‹ä»¶")
            else:
                print(f"      âŒ æ—¥æœŸä¸åœ¨èŒƒå›´å†…: {item_date}")
        
        print(f"      ğŸ“Š Aè‚¡å…¬å‘Šå¤„ç†å®Œæˆ: {len(events)} ä¸ªæœ‰æ•ˆäº‹ä»¶")
        return events

    
    
    def _process_eastmoney_nbjb(self, nbjb_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†å¹´æŠ¥å­£æŠ¥"""
        events = []
        for item in nbjb_data:
            if not item:
                continue
            item_date = self._extract_date_fixed(item.get('REPORT_DATE'))
            if item_date and start_date <= item_date <= end_date:
                event = StandardizedEvent(
                    platform="eastmoney",
                    event_id=f"em_nbjb_{item.get('SECURITY_CODE', '')}_{item_date.replace('-', '')}",
                    original_id=item.get('SECURITY_CODE', ''),
                    event_date=item_date,
                    title=f"{item.get('SECURITY_NAME_ABBR', '')} {item.get('REPORT_TYPE', '')}",
                    content=f"æŠ¥å‘Šç±»å‹: {item.get('REPORT_TYPE', '')}, æŠ¥å‘ŠæœŸ: {item.get('REPORT_PERIOD', '')}",
                    category='å¹´æŠ¥å­£æŠ¥',
                    importance=4,
                    country='ä¸­å›½',
                    stocks=[item.get('SECURITY_CODE', '')] if item.get('SECURITY_CODE') else [],
                    raw_data=item
                )
                events.append(event)
        return events
    
    def _process_eastmoney_jjsj(self, jjsj_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†ç»æµæ•°æ®"""
        events = []
        for item in jjsj_data:
            if not item:
                continue
            item_date = self._extract_date_fixed(item.get('Date'))
            if item_date and start_date <= item_date <= end_date:
                data_items = item.get('Data') or []
                for data_item in data_items:
                    if not data_item:
                        continue
                    event = StandardizedEvent(
                        platform="eastmoney",
                        event_id=f"em_jjsj_{item.get('Date', '').replace('-', '').replace(' ', '').replace(':', '')}_{hash(data_item.get('Name', ''))}",
                        original_id=f"{item.get('Date')}_{data_item.get('Name')}",
                        event_date=item_date,
                        event_time=self._extract_time_fixed(item.get('Date')),
                        event_datetime=item.get('Date'),
                        title=data_item.get('Name', ''),
                        category='ç»æµæ•°æ®',
                        importance=4,
                        country=item.get('City', ''),
                        raw_data=data_item
                    )
                    events.append(event)
        return events
        
    def _process_eastmoney_hyhy(self, hyhy_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†è¡Œä¸šä¼šè®® - ä¿®å¤ç‰ˆ"""
        events = []
        
        print(f"      ğŸ” å¤„ç†è¡Œä¸šä¼šè®®: è¾“å…¥ {len(hyhy_data)} æ¡")
        
        for item in hyhy_data:
            if not item:
                continue
            
            start_event_date = self._extract_date_fixed(item.get('START_DATE'))
            end_event_date = self._extract_date_fixed(item.get('END_DATE'))
            
            print(f"      ğŸ“… ä¼šè®®: {item.get('FE_NAME', '')} ({start_event_date} ~ {end_event_date})")
            
            # æ£€æŸ¥ä¼šè®®æ˜¯å¦åœ¨æŸ¥è¯¢èŒƒå›´å†…ï¼ˆä¼šè®®å¼€å§‹æˆ–ç»“æŸæ—¥æœŸåœ¨èŒƒå›´å†…ï¼‰
            if start_event_date and (
                (start_date <= start_event_date <= end_date) or 
                (end_event_date and start_date <= end_event_date <= end_date) or
                (start_event_date <= start_date and end_event_date and end_event_date >= end_date)
            ):
                event = StandardizedEvent(
                    platform="eastmoney",
                    event_id=f"em_hyhy_{item.get('FE_CODE', '')}",
                    original_id=item.get('FE_CODE', ''),
                    event_date=start_event_date,
                    title=item.get('FE_NAME', ''),
                    content=item.get('CONTENT', ''),
                    category='è¡Œä¸šä¼šè®®',
                    importance=3,
                    country='ä¸­å›½',
                    city=item.get('CITY'),
                    raw_data={
                        'fe_code': item.get('FE_CODE'),
                        'fe_name': item.get('FE_NAME'),
                        'start_date': start_event_date,
                        'end_date': end_event_date,
                        'fe_type': item.get('FE_TYPE'),
                        'sponsor': item.get('SPONSOR_NAME'),
                        'city': item.get('CITY'),
                        'content': item.get('CONTENT')
                    }
                )
                events.append(event)
                print(f"      âœ… åˆ›å»ºä¼šè®®äº‹ä»¶: {event.title}")
        
        print(f"      ğŸ“Š è¡Œä¸šä¼šè®®å¤„ç†å®Œæˆ: {len(events)} ä¸ªæœ‰æ•ˆäº‹ä»¶")
        return events

    
    def _process_eastmoney_gddh(self, gddh_data: list, start_date: str, end_date: str) -> List[StandardizedEvent]:
        """å¤„ç†è‚¡ä¸œå¤§ä¼š"""
        events = []
        for item in gddh_data:
            if not item:
                continue
            item_date = self._extract_date_fixed(item.get('MEETING_DATE'))
            if item_date and start_date <= item_date <= end_date:
                event = StandardizedEvent(
                    platform="eastmoney",
                    event_id=f"em_gddh_{item.get('SECURITY_CODE', '')}_{item_date.replace('-', '')}",
                    original_id=item.get('SECURITY_CODE', ''),
                    event_date=item_date,
                    event_time=self._extract_time_fixed(item.get('MEETING_DATE')),
                    event_datetime=item.get('MEETING_DATE'),
                    title=f"{item.get('SECURITY_NAME_ABBR', '')}è‚¡ä¸œå¤§ä¼š",
                    content=f"ä¼šè®®ç±»å‹: {item.get('MEETING_TYPE', '')}, åœ°ç‚¹: {item.get('MEETING_PLACE', '')}",
                    category='è‚¡ä¸œå¤§ä¼š',
                    importance=3,
                    country='ä¸­å›½',
                    city=item.get('MEETING_PLACE'),
                    stocks=[item.get('SECURITY_CODE', '')] if item.get('SECURITY_CODE') else [],
                    raw_data=item
                )
                events.append(event)
        return events

# ============================================================================
# æ•°æ®å­˜å‚¨ç®¡ç†
# ============================================================================

class DataStorage:
    """æ•°æ®å­˜å‚¨ç®¡ç†"""
    
    def __init__(self):
        self.base_path = "./data"
        self.current_path = os.path.join(self.base_path, "active", "current")
        self.previous_path = os.path.join(self.base_path, "active", "previous")
        self.archived_path = os.path.join(self.base_path, "archived")
        self._ensure_directories()
    
    def _ensure_directories(self):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        os.makedirs(self.current_path, exist_ok=True)
        os.makedirs(self.previous_path, exist_ok=True)
    
    def save_platform_data(self, platform: str, events: List[StandardizedEvent]):
        """ä¿å­˜å¹³å°æ•°æ®ä¸ºtxtæ–‡ä»¶"""
        file_path = os.path.join(self.current_path, f"{platform}.txt")
        
        data = {
            "platform": platform,
            "total_events": len(events),
            "data_status": "ACTIVE",
            "date_type": "FUTURE",
            "last_updated": datetime.now().isoformat(),
            "immutable": False,
            "events": [event.to_dict() for event in events]
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(json.dumps(data, ensure_ascii=False, indent=2))
        
        print(f"ğŸ’¾ {platform} æ•°æ®å·²ä¿å­˜åˆ° {file_path}")

    def save_all_data(self, all_data: Dict[str, List[StandardizedEvent]]):
        """ä¿å­˜æ‰€æœ‰å¹³å°æ•°æ®"""
        for platform, events in all_data.items():
            self.save_platform_data(platform, events)
        
        # ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
        self._generate_summary(all_data)
    
    def _generate_summary(self, all_data: Dict[str, List[StandardizedEvent]]):
        """ç”Ÿæˆæ•°æ®æ±‡æ€»ä¿¡æ¯"""
        summary = {
            "collection_type": "ACTIVE",
            "collection_time": datetime.now().isoformat(),
            "platforms": {},
            "total_events": 0,
            "date_range": {
                "start": None,
                "end": None
            }
        }
        
        all_dates = []
        
        for platform, events in all_data.items():
            platform_dates = [event.event_date for event in events if event.event_date]
            all_dates.extend(platform_dates)
            
            summary["platforms"][platform] = {
                "event_count": len(events),
                "date_range": {
                    "start": min(platform_dates) if platform_dates else None,
                    "end": max(platform_dates) if platform_dates else None
                }
            }
            summary["total_events"] += len(events)
        
        if all_dates:
            summary["date_range"]["start"] = min(all_dates)
            summary["date_range"]["end"] = max(all_dates)
        
        # ä¿å­˜æ±‡æ€»ä¿¡æ¯ä¸ºtxtæ–‡ä»¶
        summary_path = os.path.join(self.current_path, "metadata.txt")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(json.dumps(summary, ensure_ascii=False, indent=2))
        
        print(f"ğŸ“Š æ•°æ®æ±‡æ€»ä¿¡æ¯å·²ä¿å­˜åˆ° {summary_path}")

# ============================================================================
# äº‹ä»¶å˜æ›´æ£€æµ‹å¼•æ“
# ============================================================================

class ChangeDetectionEngine:
    """äº‹ä»¶å˜æ›´æ£€æµ‹å¼•æ“"""
    
    def __init__(self):
        self.base_path = "./data"
        self.current_path = os.path.join(self.base_path, "active", "current")
        self.previous_path = os.path.join(self.base_path, "active", "previous")
    
    def detect_all_changes_with_new_data(self, new_data: Dict[str, List[StandardizedEvent]]) -> Dict[str, Dict[str, List[StandardizedEvent]]]:
        """ä½¿ç”¨æ–°é‡‡é›†çš„æ•°æ®è¿›è¡Œå˜æ›´æ£€æµ‹"""
        platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
        all_changes = {}
        
        print("ğŸ” å¼€å§‹æ£€æµ‹äº‹ä»¶å˜æ›´...")
        print("=" * 50)
        
        total_new = 0
        total_updated = 0
        total_cancelled = 0
        
        for platform in platforms:
            print(f"\nğŸ“Š æ£€æµ‹ {platform} å¹³å°å˜æ›´...")
            
            try:
                # åŠ è½½previousæ•°æ®
                previous_events = load_platform_data(platform, self.previous_path)
                
                # ä½¿ç”¨æ–°é‡‡é›†çš„æ•°æ®ä½œä¸ºcurrent
                current_events = new_data.get(platform, [])
                
                # æ£€æµ‹å˜æ›´
                changes = self._detect_platform_changes(platform, previous_events, current_events)
                all_changes[platform] = changes
                
                # ç»Ÿè®¡
                new_count = len(changes['new_events'])
                updated_count = len(changes['updated_events'])
                cancelled_count = len(changes['cancelled_events'])
                
                total_new += new_count
                total_updated += updated_count
                total_cancelled += cancelled_count
                
                print(f"   æ–°å¢: {new_count}, æ›´æ–°: {updated_count}, å–æ¶ˆ: {cancelled_count}")
                
                # å¦‚æœæœ‰å˜æ›´ï¼Œæ ‡è®°æ–°æ•°æ®ä¸­çš„äº‹ä»¶
                if new_count > 0 or updated_count > 0:
                    self._mark_changes_in_new_data(platform, new_data[platform], changes)
                
            except Exception as e:
                print(f"âŒ {platform} å˜æ›´æ£€æµ‹å¤±è´¥: {e}")
                all_changes[platform] = {
                    'new_events': [],
                    'updated_events': [],
                    'cancelled_events': []
                }
        
        # ç”Ÿæˆå˜æ›´æŠ¥å‘Š
        self._generate_change_report(all_changes, total_new, total_updated, total_cancelled)
        
        return all_changes
    
    def _detect_platform_changes(self, platform: str, previous_events: List[StandardizedEvent], 
                                current_events: List[StandardizedEvent]) -> Dict[str, List[StandardizedEvent]]:
        """æ£€æµ‹å•ä¸ªå¹³å°çš„å˜æ›´"""
        
        # æ„å»ºäº‹ä»¶æ˜ å°„
        prev_map = {self._generate_event_key(event): event for event in previous_events}
        curr_map = {self._generate_event_key(event): event for event in current_events}
        
        new_events = []
        updated_events = []
        cancelled_events = []
        
        today = datetime.now().strftime('%Y-%m-%d')
        
        # æ£€æµ‹æ–°å¢å’Œæ›´æ–°äº‹ä»¶
        for key, curr_event in curr_map.items():
            if curr_event.event_date >= today:
                if key not in prev_map:
                    # æ–°å¢äº‹ä»¶
                    new_events.append(curr_event)
                else:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹æ›´æ–°
                    prev_event = prev_map[key]
                    if self._has_content_changed(prev_event, curr_event):
                        updated_events.append(curr_event)
        
        # æ£€æµ‹å–æ¶ˆäº‹ä»¶
        for key, prev_event in prev_map.items():
            if prev_event.event_date >= today and key not in curr_map:
                cancelled_events.append(prev_event)
        
        return {
            'new_events': new_events,
            'updated_events': updated_events,
            'cancelled_events': cancelled_events
        }
    
    def _mark_changes_in_new_data(self, platform: str, current_events: List[StandardizedEvent], 
                                 changes: Dict[str, List[StandardizedEvent]]):
        """åœ¨æ–°æ•°æ®ä¸­æ ‡è®°å˜æ›´äº‹ä»¶"""
        today = datetime.now().strftime('%Y-%m-%d')
        
        # æ ‡è®°æ–°å¢äº‹ä»¶
        new_event_keys = {self._generate_event_key(event) for event in changes['new_events']}
        
        # æ ‡è®°æ›´æ–°äº‹ä»¶
        updated_event_keys = {self._generate_event_key(event) for event in changes['updated_events']}
        
        for event in current_events:
            event_key = self._generate_event_key(event)
            
            if event_key in new_event_keys:
                event.is_new = True
                event.discovery_date = today
            elif event_key in updated_event_keys:
                event.discovery_date = today
    
    def _generate_event_key(self, event: StandardizedEvent) -> str:
        """ç”Ÿæˆäº‹ä»¶å”¯ä¸€æ ‡è¯†"""
        if event.platform == "cls":
            return f"{event.original_id}_{event.event_date}_{event.category}"
        elif event.platform == "jiuyangongshe":
            return f"{event.original_id}_{event.event_date}"
        elif event.platform == "tonghuashun":
            return f"{event.event_date}_{hashlib.md5(event.title.encode()).hexdigest()[:8]}"
        elif event.platform == "investing":
            return f"{event.raw_data.get('event_attr_id', '')}_{event.event_date}_{event.event_time}"
        elif event.platform == "eastmoney":
            return f"{event.original_id}_{event.event_date}"
        else:
            return f"{event.event_id}"
    
    def _has_content_changed(self, prev_event: StandardizedEvent, curr_event: StandardizedEvent) -> bool:
        """æ£€æµ‹å†…å®¹æ˜¯å¦å˜æ›´"""
        return (
            prev_event.title != curr_event.title or
            prev_event.event_datetime != curr_event.event_datetime or
            prev_event.importance != curr_event.importance or
            prev_event.content != curr_event.content or
            prev_event.country != curr_event.country
        )
    
    def _generate_change_report(self, all_changes: Dict[str, Dict[str, List[StandardizedEvent]]], 
                              total_new: int, total_updated: int, total_cancelled: int):
        """ç”Ÿæˆå˜æ›´æŠ¥å‘Š"""
        today = datetime.now().strftime('%Y-%m-%d')
        
        report = {
            "detection_time": datetime.now().isoformat(),
            "summary": {
                "total_new": total_new,
                "total_updated": total_updated,
                "total_cancelled": total_cancelled
            },
            "platforms": {}
        }
        
        # æ”¶é›†æ‰€æœ‰æ–°å¢äº‹ä»¶ç”¨äºæ’åº
        all_new_events = []
        
        for platform, changes in all_changes.items():
            new_count = len(changes['new_events'])
            updated_count = len(changes['updated_events'])
            cancelled_count = len(changes['cancelled_events'])
            
            report["platforms"][platform] = {
                "new_events": new_count,
                "updated_events": updated_count,
                "cancelled_events": cancelled_count,
                "sample_new_titles": [event.title[:50] for event in changes['new_events'][:3]]
            }
            
            all_new_events.extend(changes['new_events'])
        
        # æŒ‰é‡è¦æ€§æ’åºæ–°å¢äº‹ä»¶
        all_new_events.sort(key=lambda x: x.importance or 0, reverse=True)
        report["top_new_events"] = [
            {
                "platform": event.platform,
                "date": event.event_date,
                "title": event.title,
                "importance": event.importance,
                "country": event.country
            }
            for event in all_new_events[:10]
        ]
        
        # ä¿å­˜å˜æ›´æŠ¥å‘Š
        report_path = os.path.join(self.current_path, f"change_report_{today}.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(json.dumps(report, ensure_ascii=False, indent=2))
        
        print(f"\nğŸ“‹ å˜æ›´æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_path}")
        
        # æ‰“å°ç»Ÿè®¡
        print(f"\nğŸ“ˆ ä»Šæ—¥å˜æ›´ç»Ÿè®¡:")
        print(f"   æ–°å¢äº‹ä»¶: {total_new} ä¸ª")
        print(f"   æ›´æ–°äº‹ä»¶: {total_updated} ä¸ª")
        print(f"   å–æ¶ˆäº‹ä»¶: {total_cancelled} ä¸ª")

# ============================================================================
# æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
# ============================================================================

class DataLifecycleManager:
    """æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨"""
    
    def __init__(self):
        self.base_path = "./data"
        self.current_path = os.path.join(self.base_path, "active", "current")
        self.previous_path = os.path.join(self.base_path, "active", "previous")
        self.archived_path = os.path.join(self.base_path, "archived")
    
    def archive_specific_date_data(self, target_date: str):
        """å½’æ¡£æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
        print(f"ğŸ“¦ å½’æ¡£ {target_date} çš„æ•°æ®...")
        
        target_dt = datetime.strptime(target_date, '%Y-%m-%d')
        year, month = target_dt.year, target_dt.month
        
        platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
        archived_count = 0
        
        for platform in platforms:
            # ä»currentä¸­æå–ç›®æ ‡æ—¥æœŸçš„æ•°æ®
            current_events = load_platform_data(platform, self.current_path)
            target_date_events = [
                event for event in current_events 
                if event.event_date == target_date
            ]
            
            if target_date_events:
                # æ ‡è®°ä¸ºå·²å½’æ¡£
                for event in target_date_events:
                    event.data_status = "ARCHIVED"
                
                # ä¿å­˜åˆ°å½’æ¡£ç›®å½•
                self._append_to_archive(platform, year, month, target_date_events)
                archived_count += len(target_date_events)
                
                print(f"   ğŸ“¦ {platform}: {len(target_date_events)} ä¸ªäº‹ä»¶å·²å½’æ¡£")
        
        print(f"âœ… {target_date} å…±å½’æ¡£ {archived_count} ä¸ªäº‹ä»¶")
    
    def rotate_future_data_only(self, archive_date: str):
        """ç²¾ç¡®è½®è½¬ï¼šåªç§»åŠ¨æœªæ¥æ•°æ®åˆ°previous"""
        print(f"ğŸ”„ è½®è½¬æœªæ¥æ•°æ®ï¼ˆæ’é™¤ {archive_date}ï¼‰...")
        
        # æ¸…ç©ºå¹¶é‡å»ºpreviousç›®å½•
        if os.path.exists(self.previous_path):
            shutil.rmtree(self.previous_path)
        os.makedirs(self.previous_path, exist_ok=True)
        
        platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
        
        for platform in platforms:
            current_events = load_platform_data(platform, self.current_path)
            
            # ç­›é€‰ï¼šåªè¦archive_dateä¹‹åçš„æ•°æ®
            future_events = [
                event for event in current_events 
                if event.event_date > archive_date
            ]
            
            print(f"   ğŸ“‹ {platform}: {len(future_events)} ä¸ªæœªæ¥äº‹ä»¶ç§»è‡³previous")
            
            # ä¿å­˜åˆ°previous
            if future_events:
                self._save_platform_data_to_path(platform, future_events, self.previous_path)
    
    def _save_platform_data_to_path(self, platform: str, events: List[StandardizedEvent], target_path: str):
        """ä¿å­˜å¹³å°æ•°æ®åˆ°æŒ‡å®šè·¯å¾„"""
        file_path = os.path.join(target_path, f"{platform}.txt")
        
        data = {
            "platform": platform,
            "total_events": len(events),
            "data_status": "ACTIVE",
            "date_type": "FUTURE",
            "last_updated": datetime.now().isoformat(),
            "immutable": False,
            "events": [event.to_dict() for event in events]
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(json.dumps(data, ensure_ascii=False, indent=2))
    
    def _append_to_archive(self, platform: str, year: int, month: int, events: List[StandardizedEvent]):
        """ä¿å­˜æ•°æ®åˆ°å½’æ¡£ç›®å½•"""
        month_path = os.path.join(self.archived_path, str(year), f"{month:02d}æœˆ")
        os.makedirs(month_path, exist_ok=True)
        
        file_path = os.path.join(month_path, f"{platform}.txt")
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
        existing_events = []
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    existing_data = json.loads(f.read())
                    for event_data in existing_data.get('events', []):
                        existing_events.append(StandardizedEvent(**event_data))
            except:
                pass
        
        # åˆå¹¶å¹¶å»é‡
        all_events = existing_events + events
        seen_ids = set()
        unique_events = []
        for event in all_events:
            if event.event_id not in seen_ids:
                unique_events.append(event)
                seen_ids.add(event.event_id)
        
        # æ„å»ºæ•°æ®ç»“æ„
        data = {
            "platform": platform,
            "year": year,
            "month": month,
            "total_events": len(unique_events),
            "data_status": "ARCHIVED",
            "date_type": "HISTORICAL",
            "last_update": datetime.now().isoformat(),
            "immutable": True,
            "events": [event.to_dict() for event in unique_events]
        }
        
        # ä¿å­˜ä¸ºtxtæ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(json.dumps(data, ensure_ascii=False, indent=2))

# ============================================================================
# æ—¥å¸¸ä»»åŠ¡è°ƒåº¦å™¨
# ============================================================================

class DailyTaskScheduler:
    """æ—¥å¸¸ä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self):
        self.collector = FutureDataCollector()
        self.storage = DataStorage()
        self.change_detector = ChangeDetectionEngine()
        self.lifecycle_manager = DataLifecycleManager()
    
    def run_first_time(self):
        """é¦–æ¬¡è¿è¡Œï¼šåªé‡‡é›†å½“å¤©åŠæœªæ¥æ•°æ®"""
        today = datetime.now().strftime('%Y-%m-%d')
        
        print(f"ğŸš€ é¦–æ¬¡è¿è¡Œæ¨¡å¼ï¼šé‡‡é›† {today} è‡³å„å¹³å°æœ€è¿œæ—¥æœŸ")
        print("=" * 60)
        
        # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯é¦–æ¬¡è¿è¡Œ
        if not self._is_first_run():
            print("âŒ æ£€æµ‹åˆ°å·²æœ‰æ´»è·ƒæ•°æ®ï¼Œè¯·ä½¿ç”¨ --daily æ¨¡å¼")
            return False
        
        try:
            # é‡‡é›†æœªæ¥æ•°æ®ï¼ˆåŒ…å«ä»Šå¤©ï¼‰
            future_data = self.collector.collect_all_future_data()
            self.storage.save_all_data(future_data)
            
            # åˆ›å»ºé¦–æ¬¡è¿è¡Œæ ‡è®°
            self._create_first_run_marker()
            
            print("âœ… é¦–æ¬¡è¿è¡Œå®Œæˆï¼Œæ˜å¤©å¼€å§‹ä½¿ç”¨ --daily æ¨¡å¼")
            return True
            
        except Exception as e:
            print(f"âŒ é¦–æ¬¡è¿è¡Œå¤±è´¥: {e}")
            return False
    
    def run_daily_update(self):
        """æ‰§è¡Œæ¯æ—¥æ›´æ–°æµç¨‹"""
        today = datetime.now().strftime('%Y-%m-%d')
        yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        print(f"ğŸ”„ æ—¥å¸¸æ›´æ–°æ¨¡å¼ï¼šå¤„ç† {yesterday} å½’æ¡£ï¼Œé‡‡é›† {today} è‡³æœ€è¿œæ—¥æœŸ")
        print("=" * 60)
        
        try:
            # ç¬¬1æ­¥ï¼šå½’æ¡£æ˜¨å¤©çš„æ•°æ®
            print(f"\nğŸ“¦ ç¬¬1æ­¥ï¼šå½’æ¡£ {yesterday} çš„æ•°æ®")
            self.lifecycle_manager.archive_specific_date_data(yesterday)
            
            # ç¬¬2æ­¥ï¼šæ•°æ®è½®è½¬ï¼ˆåªè½®è½¬æœªæ¥æ•°æ®ï¼‰
            print(f"\nğŸ”„ ç¬¬2æ­¥ï¼šè½®è½¬æœªæ¥æ•°æ®åˆ° previous")
            self.lifecycle_manager.rotate_future_data_only(yesterday)
            
            # ç¬¬3æ­¥ï¼šé‡‡é›†æ–°çš„æœªæ¥æ•°æ®
            print(f"\nğŸ“¡ ç¬¬3æ­¥ï¼šé‡‡é›† {today} è‡³æœ€è¿œæ—¥æœŸçš„æ•°æ®")
            future_data = self.collector.collect_all_future_data()
            
            # ç¬¬4æ­¥ï¼šæ£€æµ‹äº‹ä»¶å˜æ›´
            print(f"\nğŸ” ç¬¬4æ­¥ï¼šæ£€æµ‹äº‹ä»¶å˜æ›´")
            changes = self.change_detector.detect_all_changes_with_new_data(future_data)
            
            # ç¬¬5æ­¥ï¼šä¿å­˜æ–°æ•°æ®åˆ°current
            print(f"\nğŸ’¾ ç¬¬5æ­¥ï¼šä¿å­˜æ–°æ•°æ®")
            self.storage.save_all_data(future_data)
            
            print("\nâœ… æ—¥å¸¸æ›´æ–°æµç¨‹å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æ—¥å¸¸æ›´æ–°æµç¨‹å¤±è´¥: {e}")
            return False
    
    def _is_first_run(self):
        """æ£€æŸ¥æ˜¯å¦ä¸ºé¦–æ¬¡è¿è¡Œ - ç®€åŒ–ç‰ˆ"""
        if not os.path.exists(self.storage.current_path):
            return True
        
        # æ£€æŸ¥å…³é”®å¹³å°æ•°æ®æ–‡ä»¶
        required_platforms = ['cls', 'jiuyangongshe', 'tonghuashun']  # è‡³å°‘éœ€è¦è¿™3ä¸ª
        valid_files = 0
        
        for platform in required_platforms:
            file_path = os.path.join(self.storage.current_path, f"{platform}.txt")
            if os.path.exists(file_path) and os.path.getsize(file_path) > 100:  # æ–‡ä»¶å­˜åœ¨ä¸”ä¸ä¸ºç©º
                valid_files += 1
        
        return valid_files < 2  # è‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆæ–‡ä»¶

    
    def _create_first_run_marker(self):
        """åˆ›å»ºé¦–æ¬¡è¿è¡Œæ ‡è®°"""
        marker_path = os.path.join(self.storage.current_path, "first_run_marker.txt")
        marker_data = {
            "first_run_date": datetime.now().strftime('%Y-%m-%d'),
            "first_run_time": datetime.now().isoformat(),
            "status": "completed"
        }
        
        with open(marker_path, 'w', encoding='utf-8') as f:
            f.write(json.dumps(marker_data, ensure_ascii=False, indent=2))

# ============================================================================
# æŸ¥è¯¢åŠŸèƒ½
# ============================================================================

def get_new_events_by_date(discovery_date: str = None) -> List[StandardizedEvent]:
    """æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ–°å¢äº‹ä»¶"""
    if discovery_date is None:
        discovery_date = datetime.now().strftime('%Y-%m-%d')
    
    all_new_events = []
    platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
    
    current_path = "./data/active/current"
    
    for platform in platforms:
        events = load_platform_data(platform, current_path)
        new_events = [
            event for event in events 
            if event.is_new and event.discovery_date == discovery_date
        ]
        all_new_events.extend(new_events)
    
    return all_new_events

def get_events_by_date(date: str) -> List[StandardizedEvent]:
    """è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰äº‹ä»¶"""
    all_events = []
    platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
    
    current_path = "./data/active/current"
    
    for platform in platforms:
        events = load_platform_data(platform, current_path)
        date_events = [event for event in events if event.event_date == date]
        all_events.extend(date_events)
    
    return all_events

def get_events_by_date_range(start_date: str, end_date: str) -> List[StandardizedEvent]:
    """è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ‰€æœ‰äº‹ä»¶"""
    all_events = []
    platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
    
    current_path = "./data/active/current"
    
    for platform in platforms:
        events = load_platform_data(platform, current_path)
        range_events = [
            event for event in events 
            if event.event_date and start_date <= event.event_date <= end_date
        ]
        all_events.extend(range_events)
    
    # æŒ‰æ—¥æœŸå’Œæ—¶é—´æ’åº
    all_events.sort(key=lambda x: (x.event_date, x.event_time or "00:00:00"))
    return all_events

def get_events_by_platform(platform: str) -> List[StandardizedEvent]:
    """æŒ‰å¹³å°è·å–äº‹ä»¶"""
    current_path = "./data/active/current"
    return load_platform_data(platform, current_path)


def print_events_summary(events: List[StandardizedEvent]):
    """æ‰“å°äº‹ä»¶æ±‡æ€»ä¿¡æ¯ï¼ˆè¯¦ç»†ç‰ˆï¼Œå…¨éƒ¨è¾“å‡ºï¼‰"""
    if not events:
        print("æ²¡æœ‰æ‰¾åˆ°äº‹ä»¶")
        return
    
    print(f"å…±æ‰¾åˆ° {len(events)} ä¸ªäº‹ä»¶:")
    print("=" * 120)
    
    # è¾“å‡ºæ‰€æœ‰äº‹ä»¶
    for i, event in enumerate(events, 1):
        # æ–°å¢æ ‡è¯†
        new_mark = "ğŸ†• " if event.is_new else "   "
        
        # é‡è¦æ€§æ˜¾ç¤º
        importance_str = "â˜…" * (event.importance or 1) if event.importance else "â˜†"
        
        # å¹³å°æ ‡è¯†
        platform_display = {
            'cls': 'è´¢è”ç¤¾',
            'jiuyangongshe': 'éŸ­ç ”å…¬ç¤¾',        
            'tonghuashun': 'åŒèŠ±é¡º',
            'investing': 'è‹±ä¸ºè´¢æƒ…',
            'eastmoney': 'ä¸œæ–¹è´¢å¯Œ'
        }.get(event.platform, event.platform)
        
        # æ ‡é¢˜è¡Œ
        title_line = f"{new_mark}{i:3d}. [{platform_display:8}] {event.event_date}"
        if event.event_time:
            title_line += f" {event.event_time}"
        title_line += f" | {importance_str}"
        
        print(title_line)
        print(f"      ğŸ“‹ {event.title}")
        
        # æ˜¾ç¤ºæ•°å€¼ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if event.content and any(keyword in event.content for keyword in ['å®é™…å€¼', 'é¢„æµ‹å€¼', 'å‰å€¼']):
            print(f"      ğŸ“Š {event.content}")
        elif event.content and len(event.content) <= 100:
            print(f"      ğŸ’¬ {event.content}")
        
        # æ˜¾ç¤ºåˆ†ç±»å’Œå›½å®¶
        info_parts = []
        if event.category:
            info_parts.append(f"ç±»åˆ«: {event.category}")
        if event.country:
            info_parts.append(f"å›½å®¶: {event.country}")
        if event.city:
            info_parts.append(f"åŸå¸‚: {event.city}")
        
        if info_parts:
            print(f"      ğŸ·ï¸  {' | '.join(info_parts)}")
        
        # æ˜¾ç¤ºç›¸å…³è‚¡ç¥¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if event.stocks and len(event.stocks) > 0:
            stocks_str = ', '.join(event.stocks[:5])  # æœ€å¤šæ˜¾ç¤º5ä¸ªè‚¡ç¥¨
            if len(event.stocks) > 5:
                stocks_str += f" ç­‰{len(event.stocks)}åªè‚¡ç¥¨"
            print(f"      ğŸ“ˆ ç›¸å…³è‚¡ç¥¨: {stocks_str}")
        
        # æ˜¾ç¤ºä¸»é¢˜æ¦‚å¿µï¼ˆå¦‚æœæœ‰ï¼‰
        if event.themes and len(event.themes) > 0:
            themes_str = ', '.join(event.themes[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªä¸»é¢˜
            if len(event.themes) > 3:
                themes_str += f" ç­‰{len(event.themes)}ä¸ªä¸»é¢˜"
            print(f"      ğŸ¯ ç›¸å…³ä¸»é¢˜: {themes_str}")
        
        # æ˜¾ç¤ºæ¦‚å¿µè‚¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if event.concepts and len(event.concepts) > 0:
            concepts_str = ', '.join([c.get('name', '') for c in event.concepts[:3] if c.get('name')])
            if len(event.concepts) > 3:
                concepts_str += f" ç­‰{len(event.concepts)}ä¸ªæ¦‚å¿µ"
            if concepts_str:
                print(f"      ğŸ’¡ ç›¸å…³æ¦‚å¿µ: {concepts_str}")
        
        # æ–°å¢äº‹ä»¶æ˜¾ç¤ºå‘ç°æ—¥æœŸ
        if event.is_new and event.discovery_date:
            print(f"      ğŸ” å‘ç°æ—¥æœŸ: {event.discovery_date}")
        
        print()  # ç©ºè¡Œåˆ†éš”
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    
    # æŒ‰å¹³å°ç»Ÿè®¡
    platform_stats = {}
    new_count = 0
    for event in events:
        platform_name = {
            'cls': 'è´¢è”ç¤¾',
            'jiuyangongshe': 'éŸ­ç ”å…¬ç¤¾', 
            'tonghuashun': 'åŒèŠ±é¡º',
            'investing': 'è‹±ä¸ºè´¢æƒ…',
            'eastmoney': 'ä¸œæ–¹è´¢å¯Œ'
        }.get(event.platform, event.platform)
        
        platform_stats[platform_name] = platform_stats.get(platform_name, 0) + 1
        if event.is_new:
            new_count += 1
    
    print("ğŸ“ˆ æŒ‰å¹³å°åˆ†å¸ƒ:")
    for platform, count in sorted(platform_stats.items()):
        print(f"   {platform}: {count} ä¸ª")
    
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    category_stats = {}
    for event in events:
        if event.category:
            category_stats[event.category] = category_stats.get(event.category, 0) + 1
    
    if category_stats:
        print("\nğŸ·ï¸  æŒ‰ç±»åˆ«åˆ†å¸ƒ:")
        for category, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
            print(f"   {category}: {count} ä¸ª")
    
    # æŒ‰é‡è¦æ€§ç»Ÿè®¡
    importance_stats = {}
    for event in events:
        importance = event.importance or 1
        importance_stats[importance] = importance_stats.get(importance, 0) + 1
    
    if importance_stats:
        print("\nâ­ æŒ‰é‡è¦æ€§åˆ†å¸ƒ:")
        for importance in sorted(importance_stats.keys(), reverse=True):
            stars = "â˜…" * importance
            count = importance_stats[importance]
            print(f"   {stars} ({importance}æ˜Ÿ): {count} ä¸ª")
    
    if new_count > 0:
        print(f"\nğŸ†• æ–°å¢äº‹ä»¶: {new_count} ä¸ª")
    
    print(f"\nâœ… å·²æ˜¾ç¤ºå…¨éƒ¨ {len(events)} ä¸ªäº‹ä»¶")

def show_system_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
    print("-" * 40)
    
    # æ£€æŸ¥æ´»è·ƒæ•°æ®
    current_path = "./data/active/current"
    if os.path.exists(current_path):
        txt_files = [f for f in os.listdir(current_path) if f.endswith('.txt') and f not in ['metadata.txt', 'first_run_marker.txt']]
        print(f"æ´»è·ƒæ•°æ®å¹³å°: {len(txt_files)} ä¸ª")
        
        total_active_events = 0
        total_new_events = 0
        
        for txt_file in txt_files:
            platform = txt_file.replace('.txt', '')
            events = load_platform_data(platform, current_path)
            new_events = [e for e in events if e.is_new]
            
            platform_name = {
                'cls': 'è´¢è”ç¤¾',
                'jiuyangongshe': 'éŸ­ç ”å…¬ç¤¾',
                'tonghuashun': 'åŒèŠ±é¡º',
                'investing': 'è‹±ä¸ºè´¢æƒ…',
                'eastmoney': 'ä¸œæ–¹è´¢å¯Œ'
            }.get(platform, platform)
            
            print(f"  {platform_name}: {len(events)} ä¸ªäº‹ä»¶ (æ–°å¢: {len(new_events)})")
            total_active_events += len(events)
            total_new_events += len(new_events)
        
        print(f"\næ´»è·ƒæ•°æ®æ€»è®¡: {total_active_events} ä¸ªäº‹ä»¶")
        if total_new_events > 0:
            print(f"æ–°å¢äº‹ä»¶æ€»è®¡: {total_new_events} ä¸ª")
    
    # æ£€æŸ¥å†å²æ•°æ®
    archived_path = "./data/archived"
    if os.path.exists(archived_path):
        total_archived_events = 0
        archived_months = 0
        archived_files = 0
        
        for year_dir in os.listdir(archived_path):
            if year_dir.isdigit():
                year_path = os.path.join(archived_path, year_dir)
                for month_dir in os.listdir(year_path):
                    if month_dir.endswith('æœˆ'):
                        archived_months += 1
                        month_path = os.path.join(year_path, month_dir)
                        txt_files = [f for f in os.listdir(month_path) if f.endswith('.txt')]
                        archived_files += len(txt_files)
                        
                        # ç»Ÿè®¡å†å²äº‹ä»¶æ•°é‡
                        for txt_file in txt_files:
                            platform = txt_file.replace('.txt', '')
                            try:
                                events = load_platform_data(platform, month_path)
                                total_archived_events += len(events)
                            except:
                                pass
        
        print(f"\nå†å²æ•°æ®: {archived_months} ä¸ªæœˆ, {archived_files} ä¸ªæ–‡ä»¶")
        print(f"å†å²äº‹ä»¶æ€»è®¡: {total_archived_events} ä¸ª")
    
    # æ£€æŸ¥æ¯”è¾ƒåŸºå‡†
    previous_path = "./data/active/previous"
    if os.path.exists(previous_path):
        txt_files = [f for f in os.listdir(previous_path) if f.endswith('.txt') and f != 'metadata.txt']
        
        total_previous_events = 0
        for txt_file in txt_files:
            platform = txt_file.replace('.txt', '')
            try:
                events = load_platform_data(platform, previous_path)
                total_previous_events += len(events)
            except:
                pass
        
        print(f"æ¯”è¾ƒåŸºå‡†: {len(txt_files)} ä¸ªå¹³å°, {total_previous_events} ä¸ªäº‹ä»¶")
    
    # æ£€æŸ¥æ•°æ®æ—¥æœŸèŒƒå›´
    print(f"\nğŸ“… æ•°æ®æ—¥æœŸèŒƒå›´:")
    try:
        all_events = []
        for platform in ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']:
            events = load_platform_data(platform, current_path)
            all_events.extend(events)
        
        if all_events:
            dates = [event.event_date for event in all_events if event.event_date]
            if dates:
                min_date = min(dates)
                max_date = max(dates)
                print(f"æ´»è·ƒæ•°æ®èŒƒå›´: {min_date} è‡³ {max_date}")
    except:
        pass


# ============================================================================
# ç¨‹åºå…¥å£
# ============================================================================
if __name__ == "__main__":
    import sys
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import requests
        from bs4 import BeautifulSoup
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print("è¯·è¿è¡Œ: pip install requests beautifulsoup4")
        sys.exit(1)
    
    print("ğŸ”„ æŠ•èµ„æ—¥å†æ—¥å¸¸æ•°æ®ç®¡ç†ç³»ç»Ÿ")
    print("=" * 50)
    
    # æ–°å¢ï¼šGitHub Actionsç¯å¢ƒæ”¯æŒ
    if os.getenv('GITHUB_ACTIONS'):
        print("ğŸ¤– GitHub Actionsç¯å¢ƒï¼Œæ‰§è¡Œæ—¥å¸¸æ›´æ–°")
        os.makedirs("./data/active", exist_ok=True)
        scheduler = DailyTaskScheduler()
        success = scheduler.run_daily_update()
        sys.exit(0 if success else 1)
    
    # åŸæœ‰çš„å‘½ä»¤è¡Œå‚æ•°å¤„ç†ä»£ç ä¿æŒä¸å˜
    if len(sys.argv) > 1:
        if sys.argv[1] == "--first-run":
            # é¦–æ¬¡è¿è¡Œæ¨¡å¼
            scheduler = DailyTaskScheduler()
            success = scheduler.run_first_time()
            if success:
                print("âœ… é¦–æ¬¡è¿è¡Œå®Œæˆ")
            else:
                sys.exit(1)
        
        elif sys.argv[1] == "--collect":
            # åªé‡‡é›†æœªæ¥æ•°æ®
            collector = FutureDataCollector()
            storage = DataStorage()
            future_data = collector.collect_all_future_data()
            storage.save_all_data(future_data)
            print("âœ… æ•°æ®é‡‡é›†å®Œæˆ")
            
        elif sys.argv[1] == "--detect":
            # åªæ‰§è¡Œå˜æ›´æ£€æµ‹
            collector = FutureDataCollector()
            detector = ChangeDetectionEngine()
            future_data = collector.collect_all_future_data()
            detector.detect_all_changes_with_new_data(future_data)
            print("âœ… å˜æ›´æ£€æµ‹å®Œæˆ")
            
        elif sys.argv[1] == "--daily":
            # æ‰§è¡Œå®Œæ•´æ—¥å¸¸æ›´æ–°
            scheduler = DailyTaskScheduler()
            success = scheduler.run_daily_update()
            if success:
                print("âœ… æ—¥å¸¸æ›´æ–°å®Œæˆ")
            else:
                sys.exit(1)
            
        elif sys.argv[1] == "--status":
            # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
            show_system_status()
            
        elif sys.argv[1] == "--new":
            # æŸ¥è¯¢æ–°å¢äº‹ä»¶
            discovery_date = sys.argv[2] if len(sys.argv) > 2 else datetime.now().strftime('%Y-%m-%d')
            try:
                datetime.strptime(discovery_date, '%Y-%m-%d')
                new_events = get_new_events_by_date(discovery_date)
                print(f"{discovery_date} æ–°å¢äº‹ä»¶:")
                print_events_summary(new_events)
            except ValueError:
                print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                sys.exit(1)
            
        elif sys.argv[1] == "--today":
            # æŸ¥è¯¢ä»Šæ—¥äº‹ä»¶
            today = datetime.now().strftime('%Y-%m-%d')
            events = get_events_by_date(today)
            print(f"ä»Šæ—¥ ({today}) äº‹ä»¶:")
            print_events_summary(events)
            
        elif sys.argv[1] == "--date":
            # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸäº‹ä»¶
            if len(sys.argv) > 2:
                query_date = sys.argv[2]
                try:
                    datetime.strptime(query_date, '%Y-%m-%d')
                    events = get_events_by_date(query_date)
                    print(f"{query_date} çš„äº‹ä»¶:")
                    print_events_summary(events)
                except ValueError:
                    print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                    sys.exit(1)
            else:
                print("âŒ è¯·æŒ‡å®šæŸ¥è¯¢æ—¥æœŸ")
                print("ç”¨æ³•: python daily_calendar.py --date YYYY-MM-DD")
                sys.exit(1)
        
        elif sys.argv[1] == "--range":
            # æŸ¥è¯¢æ—¥æœŸèŒƒå›´äº‹ä»¶
            if len(sys.argv) > 3:
                start_date = sys.argv[2]
                end_date = sys.argv[3]
                try:
                    datetime.strptime(start_date, '%Y-%m-%d')
                    datetime.strptime(end_date, '%Y-%m-%d')
                    
                    if start_date <= end_date:
                        events = get_events_by_date_range(start_date, end_date)
                        print(f"{start_date} è‡³ {end_date} çš„äº‹ä»¶:")
                        print_events_summary(events)
                    else:
                        print("âŒ å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")
                        sys.exit(1)
                except ValueError:
                    print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                    sys.exit(1)
            else:
                print("âŒ è¯·æŒ‡å®šå¼€å§‹å’Œç»“æŸæ—¥æœŸ")
                print("ç”¨æ³•: python daily_calendar.py --range YYYY-MM-DD YYYY-MM-DD")
                sys.exit(1)
        
        elif sys.argv[1] == "--platform":
            # æŒ‰å¹³å°æŸ¥è¯¢äº‹ä»¶
            if len(sys.argv) > 2:
                platform = sys.argv[2]
                valid_platforms = ['cls', 'jiuyangongshe', 'tonghuashun', 'investing', 'eastmoney']
                
                if platform in valid_platforms:
                    events = get_events_by_platform(platform)
                    platform_name = {
                        'cls': 'è´¢è”ç¤¾',
                        'jiuyangongshe': 'éŸ­ç ”å…¬ç¤¾',
                        'tonghuashun': 'åŒèŠ±é¡º',
                        'investing': 'è‹±ä¸ºè´¢æƒ…',
                        'eastmoney': 'ä¸œæ–¹è´¢å¯Œ'
                    }[platform]
                    print(f"{platform_name} çš„äº‹ä»¶:")
                    print_events_summary(events)
                else:
                    print(f"âŒ æ— æ•ˆçš„å¹³å°åç§°: {platform}")
                    print(f"å¯ç”¨å¹³å°: {', '.join(valid_platforms)}")
                    sys.exit(1)
            else:
                print("âŒ è¯·æŒ‡å®šå¹³å°åç§°")
                print("ç”¨æ³•: python daily_calendar.py --platform [cls|jiuyangongshe|tonghuashun|investing|eastmoney]")
                sys.exit(1)
        
        elif sys.argv[1] == "--help" or sys.argv[1] == "-h":
            # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
            print("æŠ•èµ„æ—¥å†æ—¥å¸¸æ•°æ®ç®¡ç†ç³»ç»Ÿ - ä½¿ç”¨è¯´æ˜")
            print("=" * 50)
            print("è¿è¡Œæ¨¡å¼:")
            print("  python daily_calendar.py --first-run     # é¦–æ¬¡è¿è¡Œæ¨¡å¼")
            print("  python daily_calendar.py --daily         # æ—¥å¸¸æ›´æ–°æ¨¡å¼")
            print("  python daily_calendar.py --collect       # åªé‡‡é›†æ•°æ®")
            print("  python daily_calendar.py --detect        # åªæ£€æµ‹å˜æ›´")
            print()
            print("æŸ¥è¯¢åŠŸèƒ½:")
            print("  python daily_calendar.py --today         # æŸ¥è¯¢ä»Šæ—¥äº‹ä»¶")
            print("  python daily_calendar.py --new [æ—¥æœŸ]     # æŸ¥è¯¢æ–°å¢äº‹ä»¶")
            print("  python daily_calendar.py --date æ—¥æœŸ      # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸ")
            print("  python daily_calendar.py --range å¼€å§‹ ç»“æŸ # æŸ¥è¯¢æ—¥æœŸèŒƒå›´")
            print("  python daily_calendar.py --platform å¹³å°  # æŒ‰å¹³å°æŸ¥è¯¢")
            print("  python daily_calendar.py --status        # ç³»ç»ŸçŠ¶æ€")
            print()
            print("å‚æ•°è¯´æ˜:")
            print("  æ—¥æœŸæ ¼å¼: YYYY-MM-DD (å¦‚: 2025-01-15)")
            print("  å¹³å°åç§°: cls, jiuyangongshe, tonghuashun, investing, eastmoney")
            print()
            print("ç¤ºä¾‹:")
            print("  python daily_calendar.py --new 2025-01-15")
            print("  python daily_calendar.py --range 2025-01-15 2025-01-17")
            print("  python daily_calendar.py --platform investing")
            
        else:
            print("âŒ æœªçŸ¥å‚æ•°ï¼Œä½¿ç”¨ --help æŸ¥çœ‹ä½¿ç”¨è¯´æ˜")
            print("å¸¸ç”¨å‘½ä»¤:")
            print("  python daily_calendar.py --first-run    # é¦–æ¬¡è¿è¡Œ")
            print("  python daily_calendar.py --daily        # æ—¥å¸¸æ›´æ–°")
            print("  python daily_calendar.py --today        # æŸ¥è¯¢ä»Šæ—¥äº‹ä»¶")
            print("  python daily_calendar.py --help         # å®Œæ•´å¸®åŠ©")
            sys.exit(1)
    else:
        # é»˜è®¤ï¼šè‡ªåŠ¨åˆ¤æ–­è¿è¡Œæ¨¡å¼
        scheduler = DailyTaskScheduler()
        if scheduler._is_first_run():
            print("ğŸ” æ£€æµ‹åˆ°é¦–æ¬¡è¿è¡Œï¼Œæ‰§è¡Œé¦–æ¬¡é‡‡é›†...")
            success = scheduler.run_first_time()
        else:
            print("ğŸ”„ æ‰§è¡Œæ—¥å¸¸æ›´æ–°...")
            success = scheduler.run_daily_update()
        
        if not success:
            sys.exit(1)
        
        print("âœ… ç¨‹åºæ‰§è¡Œå®Œæˆ")


            
